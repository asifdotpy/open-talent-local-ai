# Real Implementation: Setup & Integration Guide

**Status:** Phase 1 & 2 code created (Piper TTS + Persistent Storage)  
**Date:** December 16, 2025

---

## What's Been Created

### 1. âœ… Piper TTS Service (`app/services/tts_service.py`)
- **PiperTTSService**: Local text-to-speech synthesis
- **PhonemeService**: Phoneme extraction + viseme mapping
- Real audio generation (not mocks)
- Phoneme timing alignment
- Complete phoneme-to-viseme mapping

**Key Methods:**
```python
tts = PiperTTSService()
wav_bytes, sample_rate = tts.synthesize("Hello world")  # Real audio
phonemes = tts.extract_phonemes("Hello world")  # Phoneme list
aligned = tts.align_phonemes_with_audio(wav_bytes, "Hello world")  # Timing data
```

### 2. âœ… Persistent Storage Models (`app/models/database.py`)
- **Avatar** â€” Virtual character entity
- **Session** â€” Interview session (linked to avatars)
- **Preset** â€” Customization presets
- **Render** â€” Generated frames (with file paths)
- **Audio** â€” TTS audio files
- **Phoneme** â€” Phoneme timing data
- **Asset** â€” Uploaded avatar assets
- **Config** â€” Service configuration

### 3. âœ… Database Service Layer (`app/services/database_service.py`)
- Full CRUD operations for all entities
- Context managers for transaction handling
- Batch operations (create multiple phonemes at once)
- Soft deletes (sessions marked deleted_at)
- Health checks & statistics
- SQLite + PostgreSQL compatible

**Key Methods:**
```python
db = DatabaseService("sqlite:///./avatar.db")

# Avatars
avatar = db.get_or_create_avatar("avatar-1")
db.update_avatar_state("avatar-1", {"emotion": "happy"})

# Sessions
session = db.create_session("session-1", "avatar-1")
db.delete_session("session-1")  # Soft delete

# Audio + Phonemes
audio = db.create_audio("audio-1", "avatar-1", "Hello", "/path/audio.wav")
phonemes = db.create_phonemes_batch("audio-1", [
    {"phoneme": "AH", "start_ms": 0, "end_ms": 100},
])

# Query
audios = db.list_audios("avatar-1", limit=50)
stats = db.get_stats()  # {"avatars": 5, "sessions": 3, ...}
```

### 4. âœ… Updated Dependencies
```
sqlalchemy==2.0.23      # ORM
alembic==1.13.0         # Migrations
piper-tts==2024.1.0     # Neural TTS
onnxruntime==1.17.0     # ONNX inference
librosa==0.10.0         # Audio processing
soundfile==0.12.1       # WAV I/O
werkzeug==3.0.0         # Utilities
```

---

## Installation & Setup

### Step 1: Install Dependencies

```bash
cd /home/asif1/open-talent/services/avatar-service

# Install Python packages
pip install -r requirements.txt

# Verify installations
piper --version
python -c "import sqlalchemy; print(sqlalchemy.__version__)"
```

### Step 2: Initialize Database

```bash
# Auto-creates tables on first service start
# Or manually:
python << 'EOF'
from app.models.database import Base, engine
Base.metadata.create_all(engine)
print("âœ… Database initialized")
EOF
```

### Step 3: Download Piper Model (First Time)

```bash
# Download TTS model (~200MB)
piper --model en_US-glow-tts --output_file /tmp/test.wav <<< "hello"

# Or specify model path in environment
export PIPER_MODEL_PATH=~/.cache/piper/en_US-glow-tts.onnx
```

### Step 4: Verify Node.js & FFmpeg (for Phase 3)

```bash
node --version      # Should be v14+
ffmpeg -version     # Should be available
```

---

## Integration with Existing Endpoints

### Updated Lipsync Endpoint (Example)

**BEFORE (Mock):**
```python
@router.post("/lipsync")
async def lipsync(payload: LipsyncRequest):
    avatar_id = payload.avatar_id or "temp-avatar"
    phonemes = [
        {"phoneme": "HH", "t": 0.0},
        {"phoneme": "AH", "t": 0.12},
    ]
    return {"avatar_id": avatar_id, "phonemes": phonemes}
```

**AFTER (Real):**
```python
from app.services.tts_service import PhonemeService
from app.services.database_service import DatabaseService

# Initialize once (in main.py or dependency injection)
phoneme_service = PhonemeService()
db_service = DatabaseService()

@router.post("/lipsync")
async def lipsync(payload: LipsyncRequest):
    avatar_id = payload.avatar_id or "temp-avatar"
    
    # Ensure avatar exists
    db_service.get_or_create_avatar(avatar_id)
    
    # Real synthesis + phoneme extraction
    wav_bytes, phonemes = phoneme_service.synthesize_and_extract_phonemes(payload.text)
    
    # Save audio to disk
    import uuid
    from pathlib import Path
    audio_id = str(uuid.uuid4())
    audio_dir = Path("./output/audios")
    audio_dir.mkdir(parents=True, exist_ok=True)
    audio_path = audio_dir / f"{audio_id}.wav"
    audio_path.write_bytes(wav_bytes)
    
    # Store in database
    duration_ms = int(len(wav_bytes) / 88200 * 1000)  # estimate
    db_audio = db_service.create_audio(
        audio_id=audio_id,
        avatar_id=avatar_id,
        text=payload.text,
        file_path=str(audio_path),
        duration_ms=duration_ms
    )
    
    # Store phonemes
    db_service.create_phonemes_batch(audio_id, phonemes)
    
    return {
        "avatar_id": avatar_id,
        "audio_id": audio_id,
        "audio_url": f"/audios/{audio_id}.wav",
        "phonemes": phonemes,
        "duration_ms": duration_ms
    }
```

---

## Testing the Integration

### Verify TTS Service Works

```bash
cd /home/asif1/open-talent/services/avatar-service
python << 'EOF'
from app.services.tts_service import PiperTTSService, PhonemeService

# Test TTS
tts = PiperTTSService()
try:
    wav_bytes, sample_rate = tts.synthesize("Hello world, this is a test.")
    print(f"âœ… TTS works: generated {len(wav_bytes)} bytes at {sample_rate}Hz")
except Exception as e:
    print(f"âŒ TTS failed: {e}")

# Test phoneme extraction
phoneme_service = PhonemeService(tts)
text = "Hello"
phonemes = phoneme_service.tts.extract_phonemes(text)
print(f"âœ… Extracted {len(phonemes)} phonemes from '{text}'")
for p in phonemes:
    print(f"  - {p}")
EOF
```

### Verify Database Works

```bash
python << 'EOF'
from app.services.database_service import DatabaseService

db = DatabaseService("sqlite:///./avatar_test.db")

# Create avatar
avatar = db.create_avatar("test-avatar-1")
print(f"âœ… Created avatar: {avatar.avatar_id}")

# Create session
session = db.create_session("session-1", "test-avatar-1")
print(f"âœ… Created session: {session.session_id}")

# Update avatar state
avatar = db.update_avatar_state("test-avatar-1", {"emotion": "happy"})
print(f"âœ… Updated avatar state: {avatar.state}")

# Get stats
stats = db.get_stats()
print(f"âœ… Database stats: {stats}")

# Health check
healthy = db.health_check()
print(f"âœ… Database health: {healthy}")
EOF
```

### Run Existing Tests (Should Still Pass)

```bash
cd /home/asif1/open-talent

# Phase 1 + 2 tests should still pass
# (they test the API contract, not implementation details)
python -m pytest services/avatar-service/tests/test_avatar_*.py -v

# Expected: 115 passing tests (100%)
```

---

## Next Steps: Update All Endpoints

The integration pattern is consistent across all endpoints:

1. **Get/create avatar** â†’ `db_service.get_or_create_avatar(avatar_id)`
2. **Call real service** â†’ `tts_service.synthesize()`, `renderer_service.render()`, etc.
3. **Save outputs** â†’ Write files to `./output/` directories
4. **Store metadata** â†’ `db_service.create_*()` to persist
5. **Return response** â†’ Return API contract response with file URLs

### Endpoints to Update (Priority Order)

#### HIGH PRIORITY (Powers other endpoints)
- [ ] `POST /lipsync` â€” Use PiperTTSService
- [ ] `POST /phonemes` â€” Use PhonemeService
- [ ] `POST /emotions` â€” Use database state
- [ ] `GET|PATCH /{avatar_id}/state` â€” Use database

#### MEDIUM PRIORITY (Data endpoints)
- [ ] `GET|POST /presets` â€” Use database
- [ ] `GET|POST /session` â€” Use database with soft deletes
- [ ] `GET /audios` (new) â€” List from database
- [ ] `GET /renders` (new) â€” List from database

#### LOW PRIORITY (Renderer phase)
- [ ] `POST /render` â€” Use renderer_service (Phase 3)
- [ ] `POST /customize` â€” Use database + presets

---

## File Structure After Integration

```
services/avatar-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ avatar.py        âœ… (15 Pydantic models)
â”‚   â”‚   â”œâ”€â”€ database.py      âœ… (SQLAlchemy ORM)
â”‚   â”‚   â””â”€â”€ voice.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ avatar_v1.py     ðŸ”„ (to be updated with real impl)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ tts_service.py   âœ… (PiperTTSService)
â”‚   â”‚   â””â”€â”€ database_service.py âœ… (DatabaseService)
â”‚   â””â”€â”€ main.py              ðŸ”„ (to be updated)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_avatar_*.py     âœ… (115 tests, all passing)
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ renders/
â”‚   â””â”€â”€ audios/
â”œâ”€â”€ avatar.db                (SQLite, auto-created)
â”œâ”€â”€ requirements.txt         âœ… (updated)
â””â”€â”€ README.md               (to be written)
```

---

## Environment Variables (.env)

```bash
# Database
DATABASE_URL=sqlite:///./avatar.db
# DATABASE_URL=postgresql://user:pass@localhost/avatar  # Production

# Piper TTS
PIPER_MODEL_PATH=~/.cache/piper/en_US-glow-tts.onnx
PIPER_USE_GPU=false

# File Storage
RENDERS_DIR=./output/renders
AUDIOS_DIR=./output/audios
ASSETS_DIR=./assets
MAX_FILE_SIZE=524288000  # 500MB

# Performance
MAX_RENDER_TIME=30  # seconds
MAX_TTS_TIME=30
MAX_REQUESTS=100  # per minute
```

---

## Important Notes

### âš ï¸ Test Suite Compatibility

All 115 existing tests should **still pass** because:
- Tests validate **API contract** (shape, status codes)
- Tests don't care about **implementation** (real or mock)
- Database layer is transparent to endpoints
- TTS service returns same response shape

**If a test fails:**
1. Check response status code (should be 200)
2. Check response JSON shape (must match Pydantic model)
3. Check database transaction (catch errors)
4. If all else fails: run test with database mocks

### ðŸ”„ Gradual Rollout

You can update endpoints one at a time:
- Update endpoint â†’ Run tests â†’ Commit
- Repeat for next endpoint
- No need to update everything at once

### ðŸ“Š Performance Impact

- **TTS**: First synthesis is slow (~5s), cached thereafter
- **Database**: SQLite is single-threaded, use PostgreSQL for production
- **Storage**: Output files grow quickly, implement cleanup policy

### ðŸ” Security Considerations

- File paths: Normalize with `Path.resolve()` + `relative_to()`
- Database: Use parameterized queries (SQLAlchemy handles this)
- API: Existing security tests still apply

---

## Troubleshooting

### "piper: command not found"
```bash
pip install piper-tts
# Or check PATH
which piper
python -m piper_tts --version
```

### "ModuleNotFoundError: No module named 'sqlalchemy'"
```bash
pip install sqlalchemy==2.0.23
```

### Database locked errors
```bash
# SQLite issue - ensure single process accessing DB
# Use context managers to ensure connections close:
with db.get_db() as session:
    # Do work here
# Automatically commits/closes
```

### TTS takes too long
```bash
# First synthesis: ~5s (model loading)
# Subsequent: <1s (cached)
# Consider caching or pre-generating common phrases
```

---

## Success Checklist

- [ ] Dependencies installed (`pip install -r requirements.txt`)
- [ ] TTS service tested (`piper --version` works)
- [ ] Database initialized (avatar.db created)
- [ ] All 115 tests still passing
- [ ] First endpoint updated (e.g., `/lipsync`)
- [ ] New endpoint returns real data (check `/output/` directories)
- [ ] Database query works (check avatar.db with sqlite3)
- [ ] All endpoints updated
- [ ] Ready for Phase 3 (Renderer)

---

## Next: Phase 3 (Renderer Integration)

Once all endpoints are using real services:
1. Create `renderer_service.py` (Node.js wrapper)
2. Create `asset_service.py` (file serving)
3. Update `/render` endpoint to use actual rendering
4. Add asset upload/download endpoints

See [REAL_IMPLEMENTATION_ROADMAP.md](REAL_IMPLEMENTATION_ROADMAP.md) for detailed Phase 3 plan.

---

**Ready to start updating endpoints? Pick one (e.g., `/lipsync`) and we'll walk through the integration step-by-step.**
