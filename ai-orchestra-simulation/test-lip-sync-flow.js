#!/usr/bin/env node

import fetch from 'node-fetch';
import WebSocket from 'ws';

// Test the complete flow: TTS -> WebSocket -> Avatar Renderer
async function testLipSyncFlow() {
  console.log('ðŸŽ­ Testing Lip-Sync Flow: TTS â†’ WebSocket â†’ Avatar Renderer\n');

  try {
    // Step 1: Get TTS data with phonemes
    console.log('ðŸ“¢ Step 1: Requesting TTS with phoneme extraction...');
    const ttsResponse = await fetch('http://localhost:8002/voice/tts', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        text: 'Hello, welcome to your AI interview.',
        voice: 'en-US',
        extract_phonemes: true
      })
    });

    if (!ttsResponse.ok) {
      throw new Error(`TTS API error: ${ttsResponse.status}`);
    }

    const ttsData = await ttsResponse.json();
    console.log(`âœ… TTS successful: ${ttsData.phonemes.length} phonemes, ${ttsData.duration}s duration\n`);

    // Step 2: Connect to WebSocket
    console.log('ðŸ”Œ Step 2: Connecting to Avatar Renderer WebSocket...');
    const ws = new WebSocket('ws://localhost:3001');

    return new Promise((resolve, reject) => {
      ws.on('open', () => {
        console.log('âœ… WebSocket connected\n');

        // Step 3: Send ready message
        console.log('ðŸ“¨ Step 3: Sending ready message...');
        ws.send(JSON.stringify({ type: 'ready' }));
      });

      ws.on('message', (data) => {
        const message = JSON.parse(data.toString());
        console.log(`ðŸ“¨ Received: ${message.type}`);

        if (message.type === 'connected') {
          console.log(`   Session ID: ${message.sessionId}`);
          console.log(`   Renderer: ${message.capabilities.type}\n`);
        }

        if (message.type === 'ready_ack') {
          console.log('âœ… Server ready for streaming\n');

          // Step 4: Send phoneme data
          console.log('ðŸŽ­ Step 4: Sending phoneme data for lip-sync...');
          let phonemeIndex = 0;

          const sendPhoneme = () => {
            if (phonemeIndex < ttsData.phonemes.length) {
              const phoneme = ttsData.phonemes[phonemeIndex];
              ws.send(JSON.stringify({
                type: 'phoneme_data',
                phonemes: [phoneme],
                audioTimestamp: phoneme.start,
                sessionId: message.sessionId
              }));

              console.log(`   Sent phoneme: ${phoneme.phoneme} (${phoneme.start}s - ${phoneme.end}s)`);
              phonemeIndex++;

              // Send next phoneme after a short delay
              setTimeout(sendPhoneme, 50);
            } else {
              console.log('\nâœ… All phonemes sent successfully!');
              console.log('ðŸŽ‰ Lip-sync flow test completed successfully!\n');

              // Close connection
              setTimeout(() => {
                ws.close();
                resolve();
              }, 1000);
            }
          };

          sendPhoneme();
        }
      });

      ws.on('error', (error) => {
        console.error('âŒ WebSocket error:', error.message);
        reject(error);
      });

      ws.on('close', () => {
        console.log('ðŸ”Œ WebSocket connection closed');
      });

      // Timeout after 30 seconds
      setTimeout(() => {
        ws.close();
        reject(new Error('Test timeout'));
      }, 30000);
    });

  } catch (error) {
    console.error('âŒ Test failed:', error.message);
    throw error;
  }
}

// Run the test
testLipSyncFlow().then(() => {
  console.log('ðŸŽŠ All tests passed! Lip-sync system is working correctly.');
  process.exit(0);
}).catch((error) => {
  console.error('ðŸ’¥ Test failed:', error.message);
  process.exit(1);
});