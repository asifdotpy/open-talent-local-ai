version: '3.8'

# Production Environment Overrides
# Usage: docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d

services:
  postgres:
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}  # Use strong password from .env
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./backups/postgres:/backups:rw  # Backup mount
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 2g
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  redis:
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
    volumes:
      - redis-data:/data
      - ./backups/redis:/backups:rw

  minio:
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_BROWSER_REDIRECT_URL=https://minio-console.yourdomain.com
    volumes:
      - minio-data:/data
      - ./backups/minio:/backups:rw
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1g

  ollama:
    volumes:
      - ollama-models:/root/.ollama
    deploy:
      resources:
        limits:
          cpus: "4.0"
          memory: 16g  # Increase for larger models
    # Uncomment for GPU support
    # runtime: nvidia
    # environment:
    #   - NVIDIA_VISIBLE_DEVICES=all

  avatar-service:
    build:
      context: ../../microservices/avatar-service
      target: production
    image: talentai/avatar-service:${VERSION:-latest}
    restart: always
    environment:
      - DEBUG=false
      - LOG_LEVEL=WARNING
      - SENTRY_DSN=${SENTRY_DSN:-}  # Error tracking
    deploy:
      replicas: 2  # Run 2 instances for HA
      resources:
        limits:
          cpus: "1.0"
          memory: 1g

  voice-service:
    build:
      context: ../../microservices/voice-service
      target: production
    image: talentai/voice-service:${VERSION:-latest}
    restart: always
    environment:
      - DEBUG=false
      - LOG_LEVEL=WARNING
    deploy:
      replicas: 2

  conversation-service:
    build:
      context: ../../microservices/conversation-service
      target: production
    image: talentai/conversation-service:${VERSION:-latest}
    restart: always
    environment:
      - DEBUG=false
      - LOG_LEVEL=WARNING
    deploy:
      replicas: 2

  interview-service:
    build:
      context: ../../microservices/interview-service
      target: production
    image: talentai/interview-service:${VERSION:-latest}
    restart: always
    environment:
      - DEBUG=false
      - LOG_LEVEL=WARNING
    deploy:
      replicas: 2

  scout-service:
    build:
      context: ../../microservices/scout-service
      target: production
    image: talentai/scout-service:${VERSION:-latest}
    restart: always
    environment:
      - DEBUG=false
      - LOG_LEVEL=WARNING
      - MOCK_EXTERNAL_APIS=false  # Use real APIs in production
    deploy:
      replicas: 2

  analytics-service:
    build:
      context: ../../microservices/analytics-service
      target: production
    image: talentai/analytics-service:${VERSION:-latest}
    restart: always
    environment:
      - DEBUG=false
      - LOG_LEVEL=WARNING
    deploy:
      replicas: 1

  celery-render-worker:
    restart: always
    environment:
      - LOG_LEVEL=WARNING
    command: >
      celery -A avatar_service.celery_app worker
      --loglevel=WARNING
      --concurrency=4
      --max-tasks-per-child=1000
      --time-limit=600
      --queues=render
    deploy:
      replicas: 2  # 2 worker instances
      resources:
        limits:
          cpus: "2.0"
          memory: 2g

  celery-beat:
    restart: always
    environment:
      - LOG_LEVEL=WARNING
    deploy:
      replicas: 1

  nginx:
    restart: always
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro  # SSL certificates
      - ./logs/nginx:/var/log/nginx:rw
    ports:
      - "80:80"
      - "443:443"
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512m

  # Backup service (runs daily)
  backup:
    image: alpine:latest
    container_name: talentai-backup
    restart: unless-stopped
    volumes:
      - postgres-data:/data/postgres:ro
      - redis-data:/data/redis:ro
      - minio-data:/data/minio:ro
      - ./backups:/backups:rw
      - ./scripts/backup.sh:/backup.sh:ro
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        apk add --no-cache postgresql-client redis curl
        while true; do
          /backup.sh
          sleep 86400  # Run daily
        done
    networks:
      - talentai-network

  # Log aggregator (optional)
  # loki:
  #   image: grafana/loki:latest
  #   container_name: talentai-loki
  #   restart: always
  #   ports:
  #     - "3100:3100"
  #   volumes:
  #     - ./monitoring/loki-config.yml:/etc/loki/local-config.yaml:ro
  #     - loki-data:/loki
  #   networks:
  #     - talentai-network

volumes:
  postgres-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /var/lib/talentai/postgres  # Persistent storage path
  redis-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /var/lib/talentai/redis
  minio-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /var/lib/talentai/minio
  ollama-models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /var/lib/talentai/ollama
  # loki-data:
  #   driver: local

networks:
  talentai-network:
    driver: bridge
