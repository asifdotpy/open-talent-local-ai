version: '3.8'

services:
  granite-interview-service:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8005:8005"
    environment:
      - HOST=0.0.0.0
      - PORT=8005
      - WORKERS=2
      - DEBUG=false
      - DEFAULT_MODEL=granite4:350m-h
      - MODEL_CACHE_DIR=/app/models
      - MAX_MODEL_MEMORY=0.8
      - TRAINING_DATA_DIR=/app/data
      - OUTPUT_DIR=/app/models/fine-tuned
      - WANDB_PROJECT=talent-ai-granite
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./models/fine-tuned:/app/models/fine-tuned
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8005/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  # Optional: Redis for caching (if needed)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  redis_data: